{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Impute Missing Values**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will practice essential data wrangling techniques using the Stack Overflow survey dataset. The primary focus is on handling missing data and ensuring data quality. You will:\n",
    "\n",
    "- **Load the Data:** Import the dataset into a DataFrame using the pandas library.\n",
    "\n",
    "- **Clean the Data:** Identify and remove duplicate entries to maintain data integrity.\n",
    "\n",
    "- **Handle Missing Values:** Detect missing values, impute them with appropriate strategies, and verify the imputation to create a complete and reliable dataset for analysis.\n",
    "\n",
    "This lab equips you with the skills to effectively preprocess and clean real-world datasets, a crucial step in any data analysis project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Apply techniques to impute missing values in the dataset.\n",
    "  \n",
    "-   Use suitable techniques to normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset Into a Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read Data**\n",
    "<p>\n",
    "The functions below will download the dataset into your browser:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Finding and Removing Duplicates\n",
    "##### Task 1: Identify duplicate rows in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in the dataset: 0\n",
      "No duplicate rows found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Check for duplicate rows in the dataset\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "\n",
    "# Display the duplicate rows if any exist\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nFirst few duplicate rows:\")\n",
    "    print(df[df.duplicated()].head())\n",
    "else:\n",
    "    print(\"No duplicate rows found in the dataset.\")\n",
    "\n",
    "# Additional information: Check which columns might be causing duplicates\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nDuplicate rows by subset of columns:\")\n",
    "    print(df.duplicated(subset=['Age', 'RemoteWork', 'YearsCodePro']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: Remove the duplicate rows from the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape: (65437, 114)\n",
      "Dataframe shape after removing duplicates: (65437, 114)\n",
      "Number of duplicate rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Get the shape before removing duplicates\n",
    "original_shape = df.shape\n",
    "print(f\"Original dataframe shape: {original_shape}\")\n",
    "\n",
    "# Remove duplicate rows and keep the first occurrence\n",
    "df_no_duplicates = df.drop_duplicates(keep='first')\n",
    "\n",
    "# Get the shape after removing duplicates\n",
    "new_shape = df_no_duplicates.shape\n",
    "print(f\"Dataframe shape after removing duplicates: {new_shape}\")\n",
    "print(f\"Number of duplicate rows removed: {original_shape[0] - new_shape[0]}\")\n",
    "\n",
    "# Use the cleaned dataframe for subsequent operations\n",
    "df = df_no_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Finding Missing Values\n",
    "##### Task 3: Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count for Each Column:\n",
      "ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10631\n",
      "                       ...  \n",
      "JobSatPoints_11        35992\n",
      "SurveyLength            9255\n",
      "SurveyEase              9199\n",
      "ConvertedCompYearly    42002\n",
      "JobSat                 36311\n",
      "Length: 114, dtype: int64\n",
      "\n",
      "Percentage of Missing Values in Each Column:\n",
      "ResponseId              0.00\n",
      "MainBranch              0.00\n",
      "Age                     0.00\n",
      "Employment              0.00\n",
      "RemoteWork             16.25\n",
      "                       ...  \n",
      "JobSatPoints_11        55.00\n",
      "SurveyLength           14.14\n",
      "SurveyEase             14.06\n",
      "ConvertedCompYearly    64.19\n",
      "JobSat                 55.49\n",
      "Length: 114, dtype: float64\n",
      "\n",
      "Columns with Missing Values:\n",
      "RemoteWork             10631\n",
      "CodingActivities       10971\n",
      "EdLevel                 4653\n",
      "LearnCode               4949\n",
      "LearnCodeOnline        16200\n",
      "                       ...  \n",
      "JobSatPoints_11        35992\n",
      "SurveyLength            9255\n",
      "SurveyEase              9199\n",
      "ConvertedCompYearly    42002\n",
      "JobSat                 36311\n",
      "Length: 109, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Check for missing values in each column\n",
    "print(\"Missing Values Count for Each Column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "print(\"\\nPercentage of Missing Values in Each Column:\")\n",
    "missing_percentage = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "print(missing_percentage)\n",
    "\n",
    "# Display columns with missing values (more than 0)\n",
    "print(\"\\nColumns with Missing Values:\")\n",
    "columns_with_missing = missing_values[missing_values > 0]\n",
    "print(columns_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4: Find out how many rows are missing in the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in RemoteWork column: 10631\n",
      "Percentage of missing values in RemoteWork column: 16.25%\n",
      "\n",
      "Sample of rows with missing RemoteWork values:\n",
      "    ResponseId                                         MainBranch  \\\n",
      "3            4                              I am learning to code   \n",
      "4            5                     I am a developer by profession   \n",
      "5            6                        I code primarily as a hobby   \n",
      "7            8                              I am learning to code   \n",
      "13          14  I used to be a developer by profession, but no...   \n",
      "\n",
      "                   Age                                         Employment  \\\n",
      "3      18-24 years old                                 Student, full-time   \n",
      "4      18-24 years old                                 Student, full-time   \n",
      "5   Under 18 years old                                 Student, full-time   \n",
      "7      18-24 years old  Student, full-time;Not employed, but looking f...   \n",
      "13     35-44 years old             Not employed, and not looking for work   \n",
      "\n",
      "   RemoteWork   Check CodingActivities  \\\n",
      "3         NaN  Apples              NaN   \n",
      "4         NaN  Apples              NaN   \n",
      "5         NaN  Apples              NaN   \n",
      "7         NaN  Apples              NaN   \n",
      "13        NaN  Apples              NaN   \n",
      "\n",
      "                                              EdLevel  \\\n",
      "3   Some college/university study without earning ...   \n",
      "4   Secondary school (e.g. American high school, G...   \n",
      "5                           Primary/elementary school   \n",
      "7   Secondary school (e.g. American high school, G...   \n",
      "13       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "\n",
      "                                            LearnCode  \\\n",
      "3   Other online resources (e.g., videos, blogs, f...   \n",
      "4   Other online resources (e.g., videos, blogs, f...   \n",
      "5   School (i.e., University, College, etc);Online...   \n",
      "7   Other online resources (e.g., videos, blogs, f...   \n",
      "13  Colleague;Other online resources (e.g., videos...   \n",
      "\n",
      "                                      LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "3   Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4   Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "5                                                 NaN  ...            NaN   \n",
      "7   Technical documentation;Video-based Online Cou...  ...            NaN   \n",
      "13  Technical documentation;Blogs;Stack Overflow;I...  ...            NaN   \n",
      "\n",
      "   JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "3             NaN            NaN            NaN             NaN   \n",
      "4             NaN            NaN            NaN             NaN   \n",
      "5             NaN            NaN            NaN             NaN   \n",
      "7             NaN            NaN            NaN             NaN   \n",
      "13            NaN            NaN            NaN             NaN   \n",
      "\n",
      "   JobSatPoints_11           SurveyLength                  SurveyEase  \\\n",
      "3              NaN               Too long                        Easy   \n",
      "4              NaN              Too short                        Easy   \n",
      "5              NaN  Appropriate in length                        Easy   \n",
      "7              NaN  Appropriate in length                   Difficult   \n",
      "13             NaN               Too long  Neither easy nor difficult   \n",
      "\n",
      "   ConvertedCompYearly JobSat  \n",
      "3                  NaN    NaN  \n",
      "4                  NaN    NaN  \n",
      "5                  NaN    NaN  \n",
      "7                  NaN    NaN  \n",
      "13                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Count missing values in the RemoteWork column\n",
    "missing_remote_work = df['RemoteWork'].isnull().sum()\n",
    "print(f\"Number of missing values in RemoteWork column: {missing_remote_work}\")\n",
    "\n",
    "# Calculate the percentage of missing values in RemoteWork column\n",
    "missing_percentage = (missing_remote_work / len(df) * 100).round(2)\n",
    "print(f\"Percentage of missing values in RemoteWork column: {missing_percentage}%\")\n",
    "\n",
    "# Display a few rows with missing RemoteWork values\n",
    "print(\"\\nSample of rows with missing RemoteWork values:\")\n",
    "print(df[df['RemoteWork'].isnull()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Imputing Missing Values\n",
    "##### Task 5: Find the value counts for the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for RemoteWork column:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    23015\n",
      "Remote                                  20831\n",
      "In-person                               10960\n",
      "NaN                                     10631\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution of RemoteWork values:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    35.17\n",
      "Remote                                  31.83\n",
      "In-person                               16.75\n",
      "NaN                                     16.25\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Get value counts for the RemoteWork column\n",
    "remote_work_counts = df['RemoteWork'].value_counts(dropna=False)\n",
    "print(\"Value counts for RemoteWork column:\")\n",
    "print(remote_work_counts)\n",
    "\n",
    "# Visualize the distribution as percentages\n",
    "remote_work_percent = df['RemoteWork'].value_counts(normalize=True, dropna=False) * 100\n",
    "print(\"\\nPercentage distribution of RemoteWork values:\")\n",
    "print(remote_work_percent.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6: Identify the most frequent (majority) value in the RemoteWork column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value in RemoteWork column: 'Hybrid (some remote, some in-person)'\n",
      "Count of most frequent value: 23015\n",
      "Percentage of most frequent value: 41.99%\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Find the most frequent value in the RemoteWork column (excluding NaN)\n",
    "most_frequent_remote_work = df['RemoteWork'].mode()[0]\n",
    "print(f\"Most frequent value in RemoteWork column: '{most_frequent_remote_work}'\")\n",
    "\n",
    "# Count occurrences of the most frequent value\n",
    "count_most_frequent = df['RemoteWork'].value_counts()[most_frequent_remote_work]\n",
    "print(f\"Count of most frequent value: {count_most_frequent}\")\n",
    "\n",
    "# Calculate percentage of the most frequent value\n",
    "percentage_most_frequent = (count_most_frequent / df['RemoteWork'].count() * 100).round(2)\n",
    "print(f\"Percentage of most frequent value: {percentage_most_frequent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 7: Impute (replace) all the empty rows in the column RemoteWork with the majority value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values with: 'Hybrid (some remote, some in-person)'\n",
      "Missing values before imputation: 10631\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Value counts after imputation:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    33646\n",
      "Remote                                  20831\n",
      "In-person                               10960\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1017/4081704489.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed['RemoteWork'].fillna(most_frequent_remote_work, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Make a copy of the dataframe to preserve the original\n",
    "df_imputed = df.copy()\n",
    "\n",
    "# Identify the most frequent value in RemoteWork column\n",
    "most_frequent_remote_work = df['RemoteWork'].mode()[0]\n",
    "print(f\"Imputing missing values with: '{most_frequent_remote_work}'\")\n",
    "\n",
    "# Count missing values before imputation\n",
    "missing_before = df_imputed['RemoteWork'].isnull().sum()\n",
    "print(f\"Missing values before imputation: {missing_before}\")\n",
    "\n",
    "# Impute missing values with the most frequent value\n",
    "df_imputed['RemoteWork'].fillna(most_frequent_remote_work, inplace=True)\n",
    "\n",
    "# Count missing values after imputation\n",
    "missing_after = df_imputed['RemoteWork'].isnull().sum()\n",
    "print(f\"Missing values after imputation: {missing_after}\")\n",
    "\n",
    "# Verify the imputation with value counts\n",
    "print(\"\\nValue counts after imputation:\")\n",
    "print(df_imputed['RemoteWork'].value_counts())\n",
    "\n",
    "# Update the main dataframe\n",
    "df = df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 8: Check for any compensation-related columns and describe their distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compensation-related columns found: []\n",
      "\n",
      "No compensation-related columns found in the dataset.\n",
      "\n",
      "All column names in the dataset:\n",
      "1. ResponseId\n",
      "2. MainBranch\n",
      "3. Age\n",
      "4. Employment\n",
      "5. RemoteWork\n",
      "6. Check\n",
      "7. CodingActivities\n",
      "8. EdLevel\n",
      "9. LearnCode\n",
      "10. LearnCodeOnline\n",
      "11. TechDoc\n",
      "12. YearsCode\n",
      "13. YearsCodePro\n",
      "14. DevType\n",
      "15. OrgSize\n",
      "16. PurchaseInfluence\n",
      "17. BuyNewTool\n",
      "18. BuildvsBuy\n",
      "19. TechEndorse\n",
      "20. Country\n",
      "21. Currency\n",
      "22. CompTotal\n",
      "23. LanguageHaveWorkedWith\n",
      "24. LanguageWantToWorkWith\n",
      "25. LanguageAdmired\n",
      "26. DatabaseHaveWorkedWith\n",
      "27. DatabaseWantToWorkWith\n",
      "28. DatabaseAdmired\n",
      "29. PlatformHaveWorkedWith\n",
      "30. PlatformWantToWorkWith\n",
      "31. PlatformAdmired\n",
      "32. WebframeHaveWorkedWith\n",
      "33. WebframeWantToWorkWith\n",
      "34. WebframeAdmired\n",
      "35. EmbeddedHaveWorkedWith\n",
      "36. EmbeddedWantToWorkWith\n",
      "37. EmbeddedAdmired\n",
      "38. MiscTechHaveWorkedWith\n",
      "39. MiscTechWantToWorkWith\n",
      "40. MiscTechAdmired\n",
      "41. ToolsTechHaveWorkedWith\n",
      "42. ToolsTechWantToWorkWith\n",
      "43. ToolsTechAdmired\n",
      "44. NEWCollabToolsHaveWorkedWith\n",
      "45. NEWCollabToolsWantToWorkWith\n",
      "46. NEWCollabToolsAdmired\n",
      "47. OpSysPersonal use\n",
      "48. OpSysProfessional use\n",
      "49. OfficeStackAsyncHaveWorkedWith\n",
      "50. OfficeStackAsyncWantToWorkWith\n",
      "51. OfficeStackAsyncAdmired\n",
      "52. OfficeStackSyncHaveWorkedWith\n",
      "53. OfficeStackSyncWantToWorkWith\n",
      "54. OfficeStackSyncAdmired\n",
      "55. AISearchDevHaveWorkedWith\n",
      "56. AISearchDevWantToWorkWith\n",
      "57. AISearchDevAdmired\n",
      "58. NEWSOSites\n",
      "59. SOVisitFreq\n",
      "60. SOAccount\n",
      "61. SOPartFreq\n",
      "62. SOHow\n",
      "63. SOComm\n",
      "64. AISelect\n",
      "65. AISent\n",
      "66. AIBen\n",
      "67. AIAcc\n",
      "68. AIComplex\n",
      "69. AIToolCurrently Using\n",
      "70. AIToolInterested in Using\n",
      "71. AIToolNot interested in Using\n",
      "72. AINextMuch more integrated\n",
      "73. AINextNo change\n",
      "74. AINextMore integrated\n",
      "75. AINextLess integrated\n",
      "76. AINextMuch less integrated\n",
      "77. AIThreat\n",
      "78. AIEthics\n",
      "79. AIChallenges\n",
      "80. TBranch\n",
      "81. ICorPM\n",
      "82. WorkExp\n",
      "83. Knowledge_1\n",
      "84. Knowledge_2\n",
      "85. Knowledge_3\n",
      "86. Knowledge_4\n",
      "87. Knowledge_5\n",
      "88. Knowledge_6\n",
      "89. Knowledge_7\n",
      "90. Knowledge_8\n",
      "91. Knowledge_9\n",
      "92. Frequency_1\n",
      "93. Frequency_2\n",
      "94. Frequency_3\n",
      "95. TimeSearching\n",
      "96. TimeAnswering\n",
      "97. Frustration\n",
      "98. ProfessionalTech\n",
      "99. ProfessionalCloud\n",
      "100. ProfessionalQuestion\n",
      "101. Industry\n",
      "102. JobSatPoints_1\n",
      "103. JobSatPoints_4\n",
      "104. JobSatPoints_5\n",
      "105. JobSatPoints_6\n",
      "106. JobSatPoints_7\n",
      "107. JobSatPoints_8\n",
      "108. JobSatPoints_9\n",
      "109. JobSatPoints_10\n",
      "110. JobSatPoints_11\n",
      "111. SurveyLength\n",
      "112. SurveyEase\n",
      "113. ConvertedCompYearly\n",
      "114. JobSat\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Identify compensation-related columns\n",
    "compensation_columns = [col for col in df.columns if 'salary' in col.lower() \n",
    "                         or 'compensation' in col.lower() \n",
    "                         or 'income' in col.lower() \n",
    "                         or 'pay' in col.lower()]\n",
    "\n",
    "print(f\"Compensation-related columns found: {compensation_columns}\")\n",
    "\n",
    "# If compensation columns are found, describe their distribution\n",
    "if compensation_columns:\n",
    "    print(\"\\nSummary statistics for compensation-related columns:\")\n",
    "    print(df[compensation_columns].describe())\n",
    "    \n",
    "    # Check for missing values in compensation columns\n",
    "    print(\"\\nMissing values in compensation columns:\")\n",
    "    print(df[compensation_columns].isnull().sum())\n",
    "    \n",
    "    # Sample data from compensation columns\n",
    "    print(\"\\nSample data from compensation columns:\")\n",
    "    print(df[compensation_columns].head())\n",
    "else:\n",
    "    print(\"\\nNo compensation-related columns found in the dataset.\")\n",
    "    \n",
    "    # Show all column names to help identify potential compensation columns\n",
    "    print(\"\\nAll column names in the dataset:\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"{i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this lab, you focused on imputing missing values in the dataset.**\n",
    "\n",
    "- Use the <code>pandas.read_csv()</code> function to load a dataset from a CSV file into a DataFrame.\n",
    "\n",
    "- Download the dataset if it's not available online and specify the correct file path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11-05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-29|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-27|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-26|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "70ab641719bca2be0bdcb38f6a8b5de7851b6e9c28d41b9407096c62e74916a6"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
